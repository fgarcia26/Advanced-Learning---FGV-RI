{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fgarcia26/Advanced-Learning---FGV-RI/blob/main/FinalProject_AdvancedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script - NightLights and Economic Growth\n",
        "\n",
        "### Final Project - Advanced Learning 2022.2 \n",
        "\n",
        "Fernanda Garcia & Julia Duó \n",
        "\n",
        "\\\\\n",
        "\n",
        "> ***Does night time satellite imagery predict GDP per capita distribution in São Paulo region?***\n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "### Data & Methodology \n",
        "\n",
        "Data comes from: \n",
        "\n",
        "\n",
        "*   NASA: https://www.ngdc.noaa.gov/eog/dmsp/downloadV4composites.html\n",
        "*   IBGE: https://www.ibge.gov.br/estatisticas/sociais/populacao22827-censo-2020-censo4.html?=t=downloads\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Outline\n",
        "\n",
        "\n",
        "\n",
        "1.   Download the necessary packages\n",
        "2.   Library\n",
        "3. Download the datasets\n",
        "4. Following the CNN code used by META\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2-AkNmf1QLKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Download the necessary packages"
      ],
      "metadata": {
        "id": "3gm4uFMoSqY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wget\n",
        "! pip install gdal\n",
        "! pip install retrying\n",
        "#! pip install cStringIO --> This package was DISCONTINUED (now, use IO)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eh0sVKR143W",
        "outputId": "25504ed8-c31e-4b85-dbd0-0d0215097c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=71709347cc81db7853e2e3b518ea2f1f862cbdfef5ac564de9139fc13943e669\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdal in /usr/local/lib/python3.8/dist-packages (2.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from retrying) (1.15.0)\n",
            "Installing collected packages: retrying\n",
            "Successfully installed retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1bo09wyjdF5"
      },
      "outputs": [],
      "source": [
        "# We first tried using the basedosdados scraping of the IBGE dataset, but it \n",
        "# did not work\n",
        "\n",
        "#! pip install basedosdados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Libraries "
      ],
      "metadata": {
        "id": "9O8CfhyGS8oQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjqHD2LZ73ci"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import basedosdados as bd\n",
        "import wget\n",
        "import time\n",
        "import os\n",
        "import os.path\n",
        "from osgeo import gdal, ogr, osr\n",
        "from scipy import ndimage\n",
        "from scipy import misc\n",
        "import io\n",
        "gdal.UseExceptions()\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "%matplotlib inline\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Download the datasets\n",
        "\n",
        "In our case, there is an image and a dataset."
      ],
      "metadata": {
        "id": "cTGwnF31TFea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQgym_gr32wL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68970fd6-f73f-4bc5-fe8a-8968e916783d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'F152000.v4b.avg_lights_x_pct.tgz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# First, we will load the image directly from the NASA website.\n",
        "\n",
        "night_image_url = 'https://www.ngdc.noaa.gov/eog/data/web_data/v4avg_lights_x_pct/F152000.v4b.avg_lights_x_pct.tgz'\n",
        "wget.download(night_image_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second, we will load the dataset from our personal device.\n",
        "\n",
        "# One possibility is to upload the dataset in github and then download \n",
        "# directly from there.\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "income_df = pd.read_excel((uploaded['/Users/fernandagarcia/Downloads/Agregado_de_setores_2000_SP_RM/S∆o Paulo1/Responsavel1_SP1.XLS']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7Jgb8yCYnD8F",
        "outputId": "71ca0781-d430-4c10-d730-02e1ad71a19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7898678-c462-4178-9a4b-06e11056224d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7898678-c462-4178-9a4b-06e11056224d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Responsavel1_SP1.XLS to Responsavel1_SP1.XLS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-16b141b0b06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mincome_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/Users/fernandagarcia/Downloads/Agregado_de_setores_2000_SP_RM/S∆o Paulo1/Responsavel1_SP1.XLS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '/Users/fernandagarcia/Downloads/Agregado_de_setores_2000_SP_RM/S∆o Paulo1/Responsavel1_SP1.XLS'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Following the CNN code used by META\n",
        "\n",
        "The CNN code used by META can be found in this link: https://dataforgood.facebook.com/dfg/docs/methodology-high-resolution-population-density-maps"
      ],
      "metadata": {
        "id": "UEQXOyITUk-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following the META code \n",
        "\n",
        "# First, we could create clusters within the IBGE database. \n",
        "# We do not need to create the wealth variable, for instance, \n",
        "# because our dataset already emcompasses the average of the \n",
        "# income in the unit of observation. \n",
        "\n",
        "# Moreover, the IBGE dataset is already divided within the \n",
        "# unit of observation that we are interested in: setor censitário.\n",
        "\n",
        "# The problem here is that, even though we could clusterize the \n",
        "# IBGE, the ShapeFile is not working to subset the data according \n",
        "# to the geolocation. \n",
        "\n",
        "cluster_all = []\n",
        "wealth_all = []\n",
        "with open(income_url) as f:\n",
        "    for line in f:\n",
        "        cluster = int(line[28:736])\n",
        "        wealth = int(column[2])\n",
        "        cluster_all.append(cluster)\n",
        "        wealth_all.append(wealth)\n",
        "\n",
        "df = pd.DataFrame({'cluster': cluster_all, 'wlthindf': wealth_all})\n",
        "cluster_avg_asset = df.groupby('cluster')['wlthindf'].median().reset_index()\n",
        "\n",
        "df_location = pd.read_csv(cluster_file)[['DHSCLUST', 'LATNUM', 'LONGNUM']]\n",
        "result = cluster_avg_asset.merge(df_location, how='inner', left_on='cluster', right_on='DHSCLUST')[['cluster', 'wlthindf', 'LATNUM', 'LONGNUM']]\n",
        "result.rename(columns={'LATNUM': 'latitude', 'LONGNUM':'longitude'}, inplace=True)\n",
        "result.to_csv('intermediate_files/rwanda_cluster_avg_asset_2010.csv', index=False)"
      ],
      "metadata": {
        "id": "8D_P3Ue6oXob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_34TL4Th32pV"
      },
      "outputs": [],
      "source": [
        "# Now, we will use the RASTER function to read our image files\n",
        "\n",
        "def read_raster(raster_file):\n",
        "    \"\"\"\n",
        "    Function\n",
        "    --------\n",
        "    read_raster\n",
        "\n",
        "    Given a raster file, get the pixel size, pixel location, and pixel value\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raster_file : string\n",
        "        Path to the raster file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_size : float\n",
        "        Pixel size\n",
        "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
        "        Longitude of the top-left point in each pixel\n",
        "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
        "        Latitude of the top-left point in each pixel\n",
        "    centroid_x_coords : numpy.ndarray  shape: (number of columns,)\n",
        "        Longitude of the centroid in each pixel\n",
        "    centroid_y_coords : numpy.ndarray  shape: (number of rows,)\n",
        "        Latitude of the centroid in each pixel\n",
        "    bands_data : numpy.ndarray  shape: (number of rows, number of columns, 1)\n",
        "        Pixel value\n",
        "    \"\"\"\n",
        "    raster_dataset = gdal.Open(raster_file, gdal.GA_ReadOnly)\n",
        "    # get project coordination\n",
        "    proj = raster_dataset.GetProjectionRef()\n",
        "    bands_data = []\n",
        "    # Loop through all raster bands\n",
        "    for b in range(1, raster_dataset.RasterCount + 1):\n",
        "        band = raster_dataset.GetRasterBand(b)\n",
        "        bands_data.append(band.ReadAsArray())\n",
        "        no_data_value = band.GetNoDataValue()\n",
        "    bands_data = np.dstack(bands_data)\n",
        "    rows, cols, n_bands = bands_data.shape\n",
        "\n",
        "    # Get the metadata of the raster\n",
        "    geo_transform = raster_dataset.GetGeoTransform()\n",
        "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = geo_transform\n",
        "    \n",
        "    # Get location of each pixel\n",
        "    x_size = 1.0 / int(round(1 / float(x_size)))\n",
        "    y_size = - x_size\n",
        "    y_index = np.arange(bands_data.shape[0])\n",
        "    x_index = np.arange(bands_data.shape[1])\n",
        "    top_left_x_coords = upper_left_x + x_index * x_size\n",
        "    top_left_y_coords = upper_left_y + y_index * y_size\n",
        "    # Add half of the cell size to get the centroid of the cell\n",
        "    centroid_x_coords = top_left_x_coords + (x_size / 2)\n",
        "    centroid_y_coords = top_left_y_coords + (y_size / 2)\n",
        "\n",
        "    return (x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data)\n",
        "\n",
        "\n",
        "# Helper function to get the pixel index of the point\n",
        "def get_cell_idx(lon, lat, top_left_x_coords, top_left_y_coords):\n",
        "    \"\"\"\n",
        "    Function\n",
        "    --------\n",
        "    get_cell_idx\n",
        "\n",
        "    Given a point location and all the pixel locations of the raster file,\n",
        "    get the column and row index of the point in the raster\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lon : float\n",
        "        Longitude of the point\n",
        "    lat : float\n",
        "        Latitude of the point\n",
        "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
        "        Longitude of the top-left point in each pixel\n",
        "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
        "        Latitude of the top-left point in each pixel\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    lon_idx : int\n",
        "        Column index\n",
        "    lat_idx : int\n",
        "        Row index\n",
        "    \"\"\"\n",
        "    lon_idx = np.where(top_left_x_coords < lon)[0][-1]\n",
        "    lat_idx = np.where(top_left_y_coords > lat)[0][-1]\n",
        "    return lon_idx, lat_idx\n",
        "\n",
        "# The code worked! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgy8TIc332bH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "aafe55f9-71e7-4561-92bf-538639116346"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-41e49aeeb83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraster_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.ngdc.noaa.gov/eog/data/web_data/v4avg_lights_x_pct/F152000.v4b.avg_lights_x_pct.tgz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left_x_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left_y_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid_x_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid_y_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# save the result in compressed format - see https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-87fad1785042>\u001b[0m in \u001b[0;36mread_raster\u001b[0;34m(raster_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mPixel\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mraster_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGA_ReadOnly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# get project coordination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraster_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetProjectionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mOpen\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;34m\"\"\"Open(char const * utf8_path, GDALAccess eAccess) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpenEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: An error occurred while creating a virtual connection to the DAP server:\nError while reading the URL: https://www.ngdc.noaa.gov/eog/data/web_data/v4avg_lights_x_pct/F152000.v4b.avg_lights_x_pct.tgz.ver.\nThe OPeNDAP server returned the following message:\nNot Found: The data source or server could not be found.\n        Often this means that the OPeNDAP server is missing or needs attention;\n        Please contact the server administrator."
          ]
        }
      ],
      "source": [
        "# Creating the raster file based on our image\n",
        "\n",
        "raster_file = 'https://www.ngdc.noaa.gov/eog/data/web_data/v4avg_lights_x_pct/F152000.v4b.avg_lights_x_pct.tgz'\n",
        "x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data = read_raster(raster_file)\n",
        "\n",
        "# save the result in compressed format - see https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html\n",
        "np.savez('intermediate_files/nightlight.npz', top_left_x_coords=top_left_x_coords, top_left_y_coords=top_left_y_coords, bands_data=bands_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_shp_extent(shp_file):\n",
        "    \"\"\"\n",
        "    Function\n",
        "    --------\n",
        "    get_shp_extent\n",
        "\n",
        "    Given a shapefile, get the extent (boundaries)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    shp_file : string\n",
        "        Path to the shapefile\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    extent : tuple\n",
        "        Boundary location of the shapefile (x_min, x_max, y_min, y_max)\n",
        "    \"\"\"\n",
        "    inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
        "    inDataSource = inDriver.Open(inShapefile, 0)\n",
        "    inLayer = inDataSource.GetLayer()\n",
        "    extent = inLayer.GetExtent()\n",
        "    x_min_shp, x_max_shp, y_min_shp, y_max_shp = extent\n",
        "    return extent"
      ],
      "metadata": {
        "id": "Ht8gf5TdwDN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions to download images from Google Maps API\n",
        "\n",
        "from retrying import retry\n",
        "\n",
        "@retry(wait_exponential_multiplier=1000, wait_exponential_max=3600000)\n",
        "def save_img(url, file_path, file_name):\n",
        "    \"\"\"\n",
        "    Function\n",
        "    --------\n",
        "    save_img\n",
        "\n",
        "    Given a url of the map, save the image\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : string\n",
        "        URL of the map from Google Map Static API\n",
        "    file_path : string\n",
        "        Folder name of the map\n",
        "    file_name : string\n",
        "        File name\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    a = urllib.urlopen(url).read()\n",
        "    b = io.StringIO(a)\n",
        "    image = ndimage.imread(b, mode='RGB')\n",
        "    # when no image exists, api will return an image with the same color. \n",
        "    # and in the center of the image, it said'Sorry. We have no imagery here'.\n",
        "    # we should drop these images if large area of the image has the same color.\n",
        "    if np.array_equal(image[:,:10,:],image[:,10:20,:]):\n",
        "        pass\n",
        "    else:\n",
        "        misc.imsave(file_path + file_name, image[50:450, :, :])\n",
        "\n",
        "# Now read in the shapefile for Rwanda and extract the edges of the country\n",
        "inShapefile = \"/Users/fernandagarcia/Downloads/3550308/3550308.SHP\"\n",
        "x_min_shp, x_max_shp, y_min_shp, y_max_shp = get_shp_extent(inShapefile)\n",
        "\n",
        "left_idx, top_idx = get_cell_idx(x_min_shp, y_max_shp, top_left_x_coords, top_left_y_coords)\n",
        "right_idx, bottom_idx = get_cell_idx(x_max_shp, y_min_shp, top_left_x_coords, top_left_y_coords)\n",
        "\n",
        "key = 'YOUR_GOOGLE_MAP_API_KEY'\n",
        "m = 1\n",
        "for i in xrange(left_idx, right_idx + 1):\n",
        "    for j in xrange(top_idx, bottom_idx + 1):\n",
        "        lon = centroid_x_coords[i]\n",
        "        lat = centroid_y_coords[j]\n",
        "        url = 'https://maps.googleapis.com/maps/api/staticmap?center=' + str(lat) + ',' + \\\n",
        "               str(lon) + '&zoom=16&size=400x500&maptype=satellite&key=' + key\n",
        "        lightness = bands_data[j, i, 0]\n",
        "        file_path = 'google_image/' + str(lightness) + '/'\n",
        "        if not os.path.isdir(file_path):\n",
        "            os.makedirs(file_path)\n",
        "        file_name = str(i) + '_' + str(j) +'.jpg'\n",
        "        save_img(url, file_path, file_name)\n",
        "        if m % 100 == 0:\n",
        "            print (m)\n",
        "        m += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "ofoy_gMKwFAg",
        "outputId": "cab8ae63-a068-40ba-957b-c2993fb70fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0a0948d8c11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Now read in the shapefile for Rwanda and extract the edges of the country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0minShapefile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/fernandagarcia/Downloads/3550308/3550308.SHP\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mx_min_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max_shp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shp_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minShapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cell_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_min_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left_x_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left_y_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-92ef8a9a7bb3>\u001b[0m in \u001b[0;36mget_shp_extent\u001b[0;34m(shp_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minDriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mogr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDriverByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ESRI Shapefile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minDataSource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minDriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minShapefile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0minLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minDataSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mextent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetExtent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx_min_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min_shp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max_shp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'GetLayer'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}